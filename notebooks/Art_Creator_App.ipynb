{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae62fb8",
   "metadata": {},
   "source": [
    "# Personal Art Creator App\n",
    "\n",
    "This notebook trains a style model on your images and then launches a simple user interface to transform new photos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ad313b",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b32bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install -q diffusers transformers accelerate peft gradio\n",
    "!pip install -q git+https://github.com/huggingface/diffusers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168dcc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cf6d36",
   "metadata": {},
   "source": [
    "## 2. (First Time Only) Train The Model\n",
    "\n",
    "**You only need to run this section ONCE.** Once the model is trained and saved, you can skip this entire section in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d21bec",
   "metadata": {},
   "source": [
    "### 2.1. Define Paths and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75f0c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# --- IMPORTANT: VERIFY THIS PATH ---\n",
    "# This should be the direct path to the folder in your Google Drive containing your training images.\n",
    "SOURCE_IMAGE_FOLDER = \"/content/drive/MyDrive/judit_art_training\" # <-- PLEASE VERIFY THIS!\n",
    "\n",
    "# --- Leave these as they are ---\n",
    "# We copy images to a temporary local folder for faster processing\n",
    "LOCAL_TRAINING_DIR = \"/content/training_images_processed\"\n",
    "# This is where your final, permanent model will be saved\n",
    "PERMANENT_MODEL_DIR_IN_DRIVE = \"/content/drive/MyDrive/MyArtStyleModel\"\n",
    "\n",
    "# Training Parameters\n",
    "BASE_MODEL_ID = \"runwayml/stable-diffusion-v1-5\"\n",
    "INSTANCE_PROMPT = \"a drawing in sks style\" # The trigger for your style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06792df",
   "metadata": {},
   "source": [
    "### 2.2. Prepare Images for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5739a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "# Create/clean the local directory\n",
    "if os.path.exists(LOCAL_TRAINING_DIR):\n",
    "    shutil.rmtree(LOCAL_TRAINING_DIR)\n",
    "os.makedirs(LOCAL_TRAINING_DIR)\n",
    "\n",
    "print(\"Copying and processing images...\")\n",
    "image_files = [f for f in os.listdir(SOURCE_IMAGE_FOLDER) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "for filename in image_files:\n",
    "    shutil.copy(os.path.join(SOURCE_IMAGE_FOLDER, filename), LOCAL_TRAINING_DIR)\n",
    "    \n",
    "    caption_filename = os.path.splitext(filename)[0] + \".txt\"\n",
    "    with open(os.path.join(LOCAL_TRAINING_DIR, caption_filename), \"w\") as f:\n",
    "        f.write(INSTANCE_PROMPT)\n",
    "        \n",
    "    image_path = os.path.join(LOCAL_TRAINING_DIR, filename)\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            img = img.convert(\"RGB\").resize((512, 512), Image.LANCZOS)\n",
    "            img.save(image_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not process {filename}: {e}\")\n",
    "\n",
    "print(f\"Processed {len(image_files)} images in {LOCAL_TRAINING_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d629ced",
   "metadata": {},
   "source": [
    "### 2.3. Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2be2273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the training script\n",
    "!wget -q -O train_dreambooth_lora.py https://raw.githubusercontent.com/huggingface/diffusers/main/examples/dreambooth/train_dreambooth_lora.py\n",
    "\n",
    "# Launch Training\n",
    "!accelerate launch train_dreambooth_lora.py \\\n",
    "  --pretrained_model_name_or_path=$BASE_MODEL_ID \\\n",
    "  --instance_data_dir=$LOCAL_TRAINING_DIR \\\n",
    "  --output_dir=$PERMANENT_MODEL_DIR_IN_DRIVE \\\n",
    "  --instance_prompt=\"$INSTANCE_PROMPT\" \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --checkpointing_steps=500 \\\n",
    "  --learning_rate=1e-4 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --max_train_steps=1500 \\\n",
    "  --seed=42\n",
    "\n",
    "print(f'\\n\\nTraining finished! Your permanent model is saved in: {PERMANENT_MODEL_DIR_IN_DRIVE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebee8cf",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. (Future Use) Launch The App\n",
    "\n",
    "**Once your model is trained, you can start here every time!** Just run the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5cc7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths (make sure these match section 2.1)\n",
    "BASE_MODEL_ID = \"runwayml/stable-diffusion-v1-5\"\n",
    "PERMANENT_MODEL_DIR_IN_DRIVE = \"/content/drive/MyDrive/MyArtStyleModel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dca03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "\n",
    "# Load the main model and apply your custom style on top\n",
    "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(BASE_MODEL_ID, torch_dtype=torch.float16).to(\"cuda\")\n",
    "pipe.load_lora_weights(PERMANENT_MODEL_DIR_IN_DRIVE)\n",
    "\n",
    "print(\"Model loaded. Ready to create art!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a618a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(input_image, style_strength):\n",
    "    \"\"\"This function takes an image and a strength value, and returns the transformed image.\"\"\"\n",
    "    if input_image is None:\n",
    "        return None\n",
    "    \n",
    "    processed_image = input_image.resize((512, 512))\n",
    "    \n",
    "    prompt = \"a drawing in sks style, high quality illustration, clear facial features\"\n",
    "    \n",
    "    generator = torch.Generator(\"cuda\").manual_seed(42)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        result_image = pipe(\n",
    "            prompt=prompt,\n",
    "            image=processed_image,\n",
    "            strength=style_strength,\n",
    "            guidance_scale=7.5,\n",
    "            generator=generator\n",
    "        ).images[0]\n",
    "        \n",
    "    return result_image\n",
    "\n",
    "# Create the Gradio interface\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"## Personal Art Style Transformer\")\n",
    "    gr.Markdown(\"Upload a photo to transform it into your unique art style.\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            source_image = gr.Image(type=\"pil\", label=\"Source Photo\")\n",
    "            strength_slider = gr.Slider(minimum=0.5, maximum=1.0, step=0.05, value=0.75, label=\"Style Strength (higher value = more stylized)\")\n",
    "            submit_button = gr.Button(\"Transform\")\n",
    "        with gr.Column():\n",
    "            output_image = gr.Image(label=\"Generated Illustration\")\n",
    "    \n",
    "    submit_button.click(transform_image, inputs=[source_image, strength_slider], outputs=output_image)\n",
    "\n",
    "# Launch the app!\n",
    "app.launch(share=True, debug=True)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
